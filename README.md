# Jetson-VLA-benchmarks

üöÄ Benchmarking **Vision-Language-Action (VLA) models** on NVIDIA Jetson and other edge AI devices.
Most existing works (e.g., NVIDIA Isaac GR00T, OpenVLA, GR00T, NanoLLM, MLC-LLM) only report performance on **desktop GPUs**.
This repo fills the gap by providing **reproducible benchmarks on edge hardware**, including performance, power, and accuracy.

---

## üìå Goals

The goal is to provide benchmarks not only for performance (latency, throughput) but also **energy efficiency and accuracy** ‚Äî areas often missing from existing reports which focus only on desktop GPUs.

At the current stage, we focus on **Jetson AGX Orin** as the primary platform.

---

## üñ•Ô∏è Target Models

- [OpenVLA](https://github.com/yanqiangmiffy/OpenVLA)
- [NVIDIA Isaac GR00T](https://github.com/NVIDIA/Isaac-GR00T)
- [~~NanoLLM~~](https://github.com/dusty-nv/nano-llm)
- ~~[MLC-LLM](https://mlc.ai/mlc-llm) (quantized deployment on Jetson)~~

---

## üìä Metrics Collected

- **Latency / FPS** ‚Äì single-batch inference time.
- **Memory usage** ‚Äì GPU/CPU RAM during inference.
- **Power consumption** ‚Äì GPU power via `tegrastats`.
- **Accuracy** ‚Äì dataset-based evaluation (task success rate, reward, top-1 acc, etc).

---

## üîß Setup

### Requirements

- NVIDIA Jetson device (AGX Orin recommended, JetPack ‚â• 6.2)
- Docker with [jetson-containers](https://github.com/dusty-nv/jetson-containers)

### Quickstart

Clone repo:

```bash
git clone https://github.com/wzqvip/Jetson-VLA-benchmarks.git
cd Jetson-VLA-benchmarks
```


## Models

### ![ ](https://img.shields.io/badge/nVIDIA-%2376B900.svg?style=for-the-badge&logo=nVIDIA&logoColor=white) GR00T

https://github.com/NVIDIA/Isaac-GR00T

NVIDIA-Isaac-GR00T-N1.5-3B
